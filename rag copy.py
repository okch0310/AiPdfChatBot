# ğŸ¤– ì¸ê³µì§€ëŠ¥ PDF Q&A ì±—ë´‡
import gradio as gr
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_text_splitters import CharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.document_loaders import PyMuPDFLoader
from langchain_community.vectorstores import FAISS
from langchain_core.runnables import RunnableMap, RunnablePassthrough, RunnableLambda

# ==================== 1ï¸âƒ£ í™˜ê²½ ì„¤ì • ====================
load_dotenv()

# LLM (OpenAI GPT-4o-mini)
llm = ChatOpenAI(model="gpt-4o-mini")

# í…ìŠ¤íŠ¸ ë¶„ë¦¬ê¸°
text_splitter = CharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=100
)

# ì„ë² ë”© ëª¨ë¸
hf_embeddings = HuggingFaceEmbeddings(
    model_name="BAAI/bge-m3",
    model_kwargs={'device': 'cpu'}
)

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
message = """
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€ì„ í•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì£¼ì–´ì§„ ë¬¸ë§¥ì„ í† ëŒ€ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
ë§Œì•½ ë¬¸ë§¥ì—ì„œ ë‹µë³€ì„ ìœ„í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´ 
`ì£¼ì–´ì§„ ì •ë³´ì—ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.` ë¼ê³  ë‹µí•˜ì„¸ìš”.
ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ìˆë‹¤ë©´ í•œê¸€ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.

## ì£¼ì–´ì§„ ë¬¸ë§¥:
{context}

## ì‚¬ìš©ì ì§ˆë¬¸:
{input}
"""

prompt_template = ChatPromptTemplate.from_messages([
    ("human", message)
])

parser = StrOutputParser()

# ì „ì—­ ë³€ìˆ˜
db = None
retriever = None
rag_chain = None


# ==================== 2ï¸âƒ£ PDF ì—…ë¡œë“œ ì²˜ë¦¬ í•¨ìˆ˜ ====================
def load_pdf(file):
    global db, retriever, rag_chain

    print("ğŸ“‚ file:", file)
    if not file:
        return "âš ï¸ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."

    try:
        # Gradio 5.xì—ì„œëŠ” íŒŒì¼ ê²½ë¡œê°€ ë¬¸ìì—´ë¡œ ì „ë‹¬ë¨
        if isinstance(file, str):
            file_path = file
        elif hasattr(file, 'path'):
            file_path = file.path
        elif hasattr(file, 'name'):
            file_path = file.name
        else:
            file_path = str(file)

        print("ğŸ“‚ file_path:", file_path)

        loader = PyMuPDFLoader(file_path)
        docs = loader.load()
        print(f"âœ… PDF í˜ì´ì§€ ìˆ˜: {len(docs)}")

        docs = text_splitter.split_documents(docs)
        db = FAISS.from_documents(docs, hf_embeddings)
        retriever = db.as_retriever(search_kwargs={"k": 3})

        # Document ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
        def format_docs(docs):
            return "\n\n".join(doc.page_content for doc in docs)

        # inputì—ì„œ ì§ˆë¬¸ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
        def get_question(input_dict):
            return input_dict["input"] if isinstance(input_dict, dict) else input_dict

        rag_chain = (
            RunnableMap({
                "context": RunnableLambda(get_question) | retriever | RunnableLambda(format_docs),
                "input": RunnablePassthrough(),
            })
            | prompt_template
            | llm
            | parser
        )

        print("âœ… RAG chain ìƒì„± ì™„ë£Œ")
        return "âœ… PDF íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œ ë° ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤."

    except Exception as e:
        print("âŒ PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:", e)
        import traceback
        traceback.print_exc()
        return f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


# ==================== 3ï¸âƒ£ ì§ˆë¬¸ ì‘ë‹µ ì²˜ë¦¬ í•¨ìˆ˜ ====================
def answer_question(question):
    if rag_chain is None:
        return "âš ï¸ PDF íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•˜ì„¸ìš”."
    if not question:
        return "âš ï¸ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
    try:
        return rag_chain.invoke({"input": question})
    except Exception as e:
        print("âŒ ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:", e)
        import traceback
        traceback.print_exc()
        return f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


# ==================== 4ï¸âƒ£ Gradio UI êµ¬ì„± ====================
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ğŸ¤– AI PDF Q&A ì±—ë´‡
    **PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ AIê°€ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤!**
    """)

    with gr.Row():
        with gr.Column(scale=1):
            file_input = gr.File(label="PDF íŒŒì¼ ì—…ë¡œë“œ")
            upload_button = gr.Button("ğŸ“¥ ì—…ë¡œë“œ ë° ì²˜ë¦¬")

        with gr.Column(scale=2):
            status_output = gr.Textbox(label="ìƒíƒœ ë©”ì‹œì§€")
            question_input = gr.Textbox(label="ì§ˆë¬¸ ì…ë ¥", placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
            submit_button = gr.Button("ğŸ’¬ ë‹µë³€ ë°›ê¸°")
            answer_output = gr.Textbox(label="AI ë‹µë³€")

    # ë²„íŠ¼ ë™ì‘ ì—°ê²°
    upload_button.click(load_pdf, inputs=file_input, outputs=status_output)
    submit_button.click(answer_question, inputs=question_input, outputs=answer_output)

demo.launch(show_error=True)

 